{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "TZ = pytz.timezone('Europe/London')\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.signal import stft\n",
    "from catboost import CatBoostClassifier\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def feature_data(raw_data: np.ndarray) -> np.ndarray:\n",
    "    means = np.mean(raw_data, axis=-1)\n",
    "    median = np.median(raw_data, axis=-1)\n",
    "    sigmas = np.std(raw_data, axis=-1)\n",
    "    percentile95 = np.percentile(raw_data, q=0.95, axis=-1)\n",
    "    percentile05 = np.percentile(raw_data, q=0.05, axis=-1)\n",
    "    fourie_means = np.array([extract_fft_features_fixed_freqs(raw_line)[0].flatten() for raw_line in raw_data])\n",
    "    return np.concatenate(\n",
    "        (means, median, sigmas, percentile95, percentile05, fourie_means), axis=-1\n",
    "    )\n",
    "\n",
    "def extract_fft_features_fixed_freqs(\n",
    "        raw_data: np.ndarray,\n",
    "        sample_rate: int = 400,\n",
    "        target_freqs: npt.ArrayLike | None = None,\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        raw_data = np.asarray(raw_data)\n",
    "\n",
    "        if target_freqs is None:\n",
    "            target_freqs = np.arange(0.01, 25.1, 0.01)\n",
    "        else:\n",
    "            target_freqs = np.asarray(target_freqs)\n",
    "        N = raw_data.shape[1]\n",
    "        freqs = np.fft.rfftfreq(N, d=1.0 / sample_rate)\n",
    "        features = []\n",
    "        for channel_data in raw_data:\n",
    "            fft_values = np.fft.rfft(channel_data)\n",
    "            fft_magnitudes = np.abs(fft_values)\n",
    "            interpolated_magnitudes = np.interp(target_freqs, freqs, fft_magnitudes)\n",
    "            features.append(interpolated_magnitudes)\n",
    "\n",
    "        features = np.array(features)\n",
    "        return features, target_freqs\n",
    "    \n",
    "def segment_time_series(\n",
    "    data: npt.ArrayLike, \n",
    "    sample_interval: int, \n",
    "    sample_shift: int\n",
    "):\n",
    "    data = np.asarray(data)\n",
    "    num_samples = data.shape[1]\n",
    "\n",
    "    num_segments = 1 + (num_samples - sample_interval) // sample_shift\n",
    "\n",
    "    segments = []\n",
    "    times = []\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * sample_shift\n",
    "        end_idx = start_idx + sample_interval\n",
    "\n",
    "        if end_idx <= num_samples:\n",
    "            segment = data[:, start_idx:end_idx]\n",
    "            segments.append(segment)\n",
    "            times.append([start_idx, end_idx])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    segments = np.array(segments)\n",
    "    times = np.array(times)\n",
    "    return segments, times\n",
    "\n",
    "def merge_intervals_by_class(\n",
    "    intervals: npt.ArrayLike, \n",
    "    labels: npt.ArrayLike,\n",
    "    labels_proba: npt.ArrayLike\n",
    "):\n",
    "    if len(intervals) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    merged_intervals = []\n",
    "    merged_labels = []\n",
    "    merged_probas = []\n",
    "    \n",
    "    current_interval = intervals[0].copy()\n",
    "    current_label = labels[0]\n",
    "    \n",
    "    counter = 1\n",
    "    sum_probs = labels_proba[0]\n",
    "    \n",
    "    for i in range(1, len(intervals)):\n",
    "        next_interval = intervals[i]\n",
    "        next_label = labels[i]\n",
    "        next_proba = labels_proba[i]\n",
    "        \n",
    "        if next_label == current_label:\n",
    "            current_interval[1] = next_interval[1]\n",
    "            sum_probs += next_proba\n",
    "            counter += 1\n",
    "        else:\n",
    "            merged_intervals.append(current_interval)\n",
    "            merged_labels.append(current_label)\n",
    "            merged_probas.append(sum_probs / counter)\n",
    "            current_interval = next_interval.copy()\n",
    "            current_label = next_label\n",
    "            sum_probs = next_proba\n",
    "            counter = 1\n",
    "    \n",
    "    merged_intervals.append(current_interval)\n",
    "    merged_labels.append(current_label)\n",
    "    merged_probas.append(sum_probs / counter)\n",
    "    \n",
    "    return np.array(merged_intervals), np.array(merged_labels), np.array(merged_probas)\n",
    "\n",
    "def assign_bins_by_majority_class(\n",
    "    intervals: npt.ArrayLike, \n",
    "    labels: npt.ArrayLike,\n",
    "    labels_prob: npt.ArrayLike,\n",
    "    max_sample: int, \n",
    "    n_bin_samples: int\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    intervals = np.asarray(intervals)\n",
    "    labels = np.asarray(labels)\n",
    "    labels_prob = np.asarray(labels_prob)\n",
    "\n",
    "    num_samples = max_sample + 1\n",
    "    N_bins = (num_samples + n_bin_samples - 1) // n_bin_samples\n",
    "\n",
    "    bins = []\n",
    "\n",
    "    for bin_index in range(N_bins):\n",
    "        bin_start = bin_index * n_bin_samples\n",
    "        bin_end = min((bin_index + 1) * n_bin_samples - 1, max_sample)\n",
    "\n",
    "        overlaps = (intervals[:, 1] >= bin_start) & (intervals[:, 0] <= bin_end)\n",
    "        bin_labels = labels[overlaps]\n",
    "        prob_labels = labels_prob[overlaps].mean(axis=0)\n",
    "\n",
    "        if len(bin_labels) == 0:\n",
    "            bin_class = 0\n",
    "            bin_class_prob = 1\n",
    "        else:\n",
    "            unique_labels, counts = np.unique(bin_labels, return_counts=True)\n",
    "            max_count = np.max(counts)\n",
    "            max_labels = unique_labels[counts == max_count]\n",
    "\n",
    "            if len(max_labels) == 1:\n",
    "                bin_class = max_labels[0]\n",
    "                bin_class_prob = prob_labels[max_labels[0]]\n",
    "            else:\n",
    "                non_zero_labels = max_labels[max_labels != 0]\n",
    "                if len(non_zero_labels) > 0:\n",
    "                    bin_class = non_zero_labels[0]\n",
    "                    bin_class_prob = prob_labels[non_zero_labels[0]]\n",
    "                else:\n",
    "                    bin_class = 0\n",
    "                    bin_class_prob = 1\n",
    "        bins.append([bin_start, bin_end, bin_class, bin_class_prob])\n",
    "    bins = np.array(bins)\n",
    "    return bins[:, :2].astype(int), bins[:, 2].astype(int), bins[:, 3].astype(float)\n",
    "\n",
    "def assign_bins_by_majority_class_with_prob(\n",
    "    intervals: npt.ArrayLike, \n",
    "    labels: npt.ArrayLike,\n",
    "    labels_prob: npt.ArrayLike,\n",
    "    max_sample: int, \n",
    "    n_bin_samples: int\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    intervals = np.asarray(intervals)\n",
    "    labels = np.asarray(labels)\n",
    "    labels_prob = np.asarray(labels_prob)\n",
    "\n",
    "    num_samples = max_sample + 1\n",
    "    N_bins = (num_samples + n_bin_samples - 1) // n_bin_samples\n",
    "\n",
    "    bins = []\n",
    "    bin_probs = []\n",
    "\n",
    "    for bin_index in range(N_bins):\n",
    "        bin_start = bin_index * n_bin_samples\n",
    "        bin_end = min((bin_index + 1) * n_bin_samples, max_sample)\n",
    "\n",
    "        overlaps = (intervals[:, 1] >= bin_start) & (intervals[:, 0] <= bin_end)\n",
    "        bin_labels = labels[overlaps]\n",
    "        prob_labels = labels_prob[overlaps].mean(axis=0)\n",
    "\n",
    "        if len(bin_labels) == 0:\n",
    "            bin_class = 0\n",
    "            bin_class_prob = np.array([1, 0, 0, 0])\n",
    "        else:\n",
    "            unique_labels, counts = np.unique(bin_labels, return_counts=True)\n",
    "            max_count = np.max(counts)\n",
    "            max_labels = unique_labels[counts == max_count]\n",
    "\n",
    "            if len(max_labels) == 1:\n",
    "                bin_class = max_labels[0]\n",
    "                bin_class_prob = prob_labels\n",
    "            else:\n",
    "                non_zero_labels = max_labels[max_labels != 0]\n",
    "                if len(non_zero_labels) > 0:\n",
    "                    bin_class = non_zero_labels[0]\n",
    "                    bin_class_prob = prob_labels\n",
    "                else:\n",
    "                    bin_class = 0\n",
    "                    bin_class_prob = np.array([1, 0, 0, 0])\n",
    "        \n",
    "        bins.append([bin_start, bin_end, bin_class])\n",
    "        bin_probs.append(bin_class_prob)\n",
    "    bins = np.array(bins)\n",
    "    bin_probs = np.array(bin_probs)\n",
    "    return bins[:, :2].astype(int), bins[:, 2].astype(int), bin_probs\n",
    "\n",
    "def read_data(file_path: str):\n",
    "    return mne.io.read_raw_edf(file_path)\n",
    "\n",
    "def predict(\n",
    "    model, \n",
    "    raw_data: np.ndarray, \n",
    "    max_time: int, \n",
    "    sample_ratio: int = 400, \n",
    "    time_interval: float = 0.5, \n",
    "    time_shift: float = 0.5, \n",
    "    bin_time: float = 1\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    sample_interval = int(sample_ratio*time_interval)\n",
    "    sample_shift = int(sample_ratio*bin_time)\n",
    "    n_bin_samples = int(sample_ratio*time_shift)\n",
    "    max_sample = int(sample_ratio*max_time)\n",
    "    \n",
    "    segments, samples = segment_time_series(raw_data, sample_interval, sample_shift)\n",
    "    X = feature_data(segments)\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_proba = model.predict_proba(X)\n",
    "    \n",
    "    samples, y_pred, y_pred_proba = assign_bins_by_majority_class(samples, y_pred, y_pred_proba, max_sample, n_bin_samples)\n",
    "    samples, y_pred, y_pred_proba = merge_intervals_by_class(samples, y_pred, y_pred_proba)\n",
    "    times, y_pred_without_0, y_pred_proba_without_0 = (samples / sample_ratio).astype(int)[y_pred != 0], y_pred[y_pred != 0], y_pred_proba[y_pred != 0]\n",
    "    return times, y_pred_without_0, y_pred_proba_without_0\n",
    "\n",
    "def predict_by_each_bin(\n",
    "    model, \n",
    "    raw_data: np.ndarray, \n",
    "    max_time: int, \n",
    "    sample_ratio: int = 400, \n",
    "    time_interval: float = 0.5, \n",
    "    time_shift: float = 0.5, \n",
    "    bin_time: float = 1\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    sample_interval = int(sample_ratio*time_interval)\n",
    "    sample_shift = int(sample_ratio*time_shift)\n",
    "    n_bin_samples = int(sample_ratio*bin_time)\n",
    "    max_sample = int(sample_ratio*max_time)\n",
    "    \n",
    "    segments, samples = segment_time_series(raw_data, sample_interval, sample_shift)\n",
    "    X = feature_data(segments)\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_proba = model.predict_proba(X)\n",
    "    \n",
    "    samples, y_pred, y_pred_proba = assign_bins_by_majority_class_with_prob(samples, y_pred, y_pred_proba, max_sample, n_bin_samples)\n",
    "    return (samples / sample_ratio), y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\bende\\Projects\\VScodeProjects\\hacathon_mejnar\\train_dataset\\ECoG_golden_standard_[15 files, 6 h each]\\Ati4x1_15m_H2O_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\bende\\AppData\\Local\\Temp\\ipykernel_16292\\3219173084.py:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  model = CatBoostClassifier().load_model(\"models\\catboost_10k_25hz.cbm\")\n"
     ]
    }
   ],
   "source": [
    "file_path = r'train_dataset\\ECoG_golden_standard_[15 files, 6 h each]\\Ati4x1_15m_H2O_6h_edited.edf'\n",
    "data = read_data(file_path)\n",
    "raw_data = data.get_data()\n",
    "\n",
    "model = CatBoostClassifier().load_model(\"models\\catboost_10k_25hz.cbm\")\n",
    "\n",
    "times, y_pred, y_pred_proba = predict(\n",
    "                   model, \n",
    "                   raw_data,\n",
    "                   data.times[-1],\n",
    "                   time_interval = 5,\n",
    "                   time_shift = 2,\n",
    "                   bin_time = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "times, y_pred, y_pred_proba = predict_by_each_bin(\n",
    "                   model, \n",
    "                   raw_data,\n",
    "                   data.times[-1],\n",
    "                   time_interval = 5, \n",
    "                   time_shift = 2,\n",
    "                   bin_time = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'NN': [],\n",
    "    'время': [],\n",
    "    'маркер': [],\n",
    "    'вероятность': []\n",
    "}\n",
    "\n",
    "start_map = {\n",
    "    1: 'ds1',\n",
    "    2: 'is1',\n",
    "    3: 'swd1'\n",
    "}\n",
    "\n",
    "end_map = {\n",
    "    1: 'ds2',\n",
    "    2: 'is2',\n",
    "    3: 'swd2'\n",
    "}\n",
    "\n",
    "for idx, ([start_time, end_time], label, prob) in enumerate(zip(times, y_pred, y_pred_proba)):\n",
    "    df['NN'] += [2*idx]\n",
    "    df['время'] += [datetime.fromtimestamp(start_time, tz=TZ).strftime('%H:%M:%S')]\n",
    "    df['маркер'] += [start_map[label]]\n",
    "    df['вероятность'] += [prob]\n",
    "    \n",
    "    df['NN'] += [2*idx + 1]\n",
    "    df['время'] += [datetime.fromtimestamp(end_time).strftime('%H:%M:%S')]\n",
    "    df['маркер'] += [end_map[label]]\n",
    "    df['вероятность'] += [prob]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>время</th>\n",
       "      <th>маркер</th>\n",
       "      <th>вероятность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01:03:36</td>\n",
       "      <td>ds1</td>\n",
       "      <td>0.637926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03:03:43</td>\n",
       "      <td>ds2</td>\n",
       "      <td>0.637926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>01:03:50</td>\n",
       "      <td>ds1</td>\n",
       "      <td>0.655097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03:04:43</td>\n",
       "      <td>ds2</td>\n",
       "      <td>0.655097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>01:05:06</td>\n",
       "      <td>ds1</td>\n",
       "      <td>0.525845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>313</td>\n",
       "      <td>08:57:55</td>\n",
       "      <td>ds2</td>\n",
       "      <td>0.588388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>06:58:20</td>\n",
       "      <td>ds1</td>\n",
       "      <td>0.650943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>315</td>\n",
       "      <td>08:58:33</td>\n",
       "      <td>ds2</td>\n",
       "      <td>0.650943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>316</td>\n",
       "      <td>06:58:44</td>\n",
       "      <td>ds1</td>\n",
       "      <td>0.731394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>317</td>\n",
       "      <td>08:59:15</td>\n",
       "      <td>ds2</td>\n",
       "      <td>0.731394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NN     время маркер  вероятность\n",
       "0      0  01:03:36    ds1     0.637926\n",
       "1      1  03:03:43    ds2     0.637926\n",
       "2      2  01:03:50    ds1     0.655097\n",
       "3      3  03:04:43    ds2     0.655097\n",
       "4      4  01:05:06    ds1     0.525845\n",
       "..   ...       ...    ...          ...\n",
       "313  313  08:57:55    ds2     0.588388\n",
       "314  314  06:58:20    ds1     0.650943\n",
       "315  315  08:58:33    ds2     0.650943\n",
       "316  316  06:58:44    ds1     0.731394\n",
       "317  317  08:59:15    ds2     0.731394\n",
       "\n",
       "[318 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
